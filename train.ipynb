{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b0f5b21c","cell_type":"code","source":"!pip install -q segmentation-models-pytorch timm albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:10.980722Z","iopub.execute_input":"2026-02-26T18:46:10.981503Z","iopub.status.idle":"2026-02-26T18:46:15.705882Z","shell.execute_reply.started":"2026-02-26T18:46:10.981467Z","shell.execute_reply":"2026-02-26T18:46:15.704997Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"id":"4fd077ee","cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport torch\nimport random\nimport albumentations as A\nimport segmentation_models_pytorch as smp\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:15.707702Z","iopub.execute_input":"2026-02-26T18:46:15.707992Z","iopub.status.idle":"2026-02-26T18:46:27.691522Z","shell.execute_reply.started":"2026-02-26T18:46:15.707957Z","shell.execute_reply":"2026-02-26T18:46:27.690966Z"}},"outputs":[],"execution_count":2},{"id":"d22199b2","cell_type":"code","source":"def set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.692288Z","iopub.execute_input":"2026-02-26T18:46:27.692671Z","iopub.status.idle":"2026-02-26T18:46:27.701193Z","shell.execute_reply.started":"2026-02-26T18:46:27.692648Z","shell.execute_reply":"2026-02-26T18:46:27.700619Z"}},"outputs":[],"execution_count":3},{"id":"1b23f2ad","cell_type":"code","source":"TRAIN_IMG = \"/kaggle/input/datasets/arunkumarkorra/hwi-dataset/Offroad_Segmentation_Training_Dataset/Offroad_Segmentation_Training_Dataset/train/Color_Images\"\nTRAIN_MASK = \"/kaggle/input/datasets/arunkumarkorra/hwi-dataset/Offroad_Segmentation_Training_Dataset/Offroad_Segmentation_Training_Dataset/train/Segmentation\"\n\nVAL_IMG = \"/kaggle/input/datasets/arunkumarkorra/hwi-dataset/Offroad_Segmentation_Training_Dataset/Offroad_Segmentation_Training_Dataset/val/Color_Images\"\nVAL_MASK = \"/kaggle/input/datasets/arunkumarkorra/hwi-dataset/Offroad_Segmentation_Training_Dataset/Offroad_Segmentation_Training_Dataset/val/Segmentation\"\n\nTEST_IMG = \"/kaggle/input/datasets/arunkumarkorra/hwi-dataset/Offroad_Segmentation_testImages/Offroad_Segmentation_testImages/Color_Images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.702001Z","iopub.execute_input":"2026-02-26T18:46:27.702245Z","iopub.status.idle":"2026-02-26T18:46:27.711034Z","shell.execute_reply.started":"2026-02-26T18:46:27.702224Z","shell.execute_reply":"2026-02-26T18:46:27.710462Z"}},"outputs":[],"execution_count":4},{"id":"fac1de32","cell_type":"code","source":"value_map = {\n    0: 0,\n    100: 1,\n    200: 2,\n    300: 3,\n    500: 4,\n    550: 5,\n    700: 6,\n    800: 7,\n    7100: 8,\n    10000: 9\n}\n\nNUM_CLASSES = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.712994Z","iopub.execute_input":"2026-02-26T18:46:27.713267Z","iopub.status.idle":"2026-02-26T18:46:27.722881Z","shell.execute_reply.started":"2026-02-26T18:46:27.713233Z","shell.execute_reply":"2026-02-26T18:46:27.722298Z"}},"outputs":[],"execution_count":5},{"id":"3b5af0c2","cell_type":"code","source":"class OffroadDataset(Dataset):\n    def __init__(self, img_dir, mask_dir=None, transform=None):\n        self.img_dir = img_dir\n        self.mask_dir = mask_dir\n        self.images = sorted(os.listdir(img_dir))\n        self.transform = transform\n\n    def convert_mask(self, mask):\n        new_mask = np.zeros_like(mask)\n        for raw, new in value_map.items():\n            new_mask[mask == raw] = new\n        return new_mask\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        img_path = os.path.join(self.img_dir, img_name)\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.mask_dir:\n            mask_path = os.path.join(self.mask_dir, img_name)\n            mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n            mask = self.convert_mask(mask)\n\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented[\"image\"]\n            mask = augmented[\"mask\"].long()\n\n            return image, mask\n        else:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n            return image, img_name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.723648Z","iopub.execute_input":"2026-02-26T18:46:27.723905Z","iopub.status.idle":"2026-02-26T18:46:27.734632Z","shell.execute_reply.started":"2026-02-26T18:46:27.723876Z","shell.execute_reply":"2026-02-26T18:46:27.734088Z"}},"outputs":[],"execution_count":6},{"id":"5cc75223","cell_type":"code","source":"train_transform = A.Compose([\n    A.Resize(512, 512),\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(p=0.4),\n    A.HueSaturationValue(p=0.3),\n    A.GaussianBlur(p=0.2),\n    A.Normalize(),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(512, 512),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.735500Z","iopub.execute_input":"2026-02-26T18:46:27.735835Z","iopub.status.idle":"2026-02-26T18:46:27.752517Z","shell.execute_reply.started":"2026-02-26T18:46:27.735803Z","shell.execute_reply":"2026-02-26T18:46:27.751972Z"}},"outputs":[],"execution_count":7},{"id":"48b80394","cell_type":"code","source":"train_dataset = OffroadDataset(TRAIN_IMG, TRAIN_MASK, train_transform)\nval_dataset = OffroadDataset(VAL_IMG, VAL_MASK, val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.753424Z","iopub.execute_input":"2026-02-26T18:46:27.754018Z","iopub.status.idle":"2026-02-26T18:46:27.809191Z","shell.execute_reply.started":"2026-02-26T18:46:27.753997Z","shell.execute_reply":"2026-02-26T18:46:27.808576Z"}},"outputs":[],"execution_count":8},{"id":"6a2b7d3f","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = smp.Segformer(\n    encoder_name=\"mit_b3\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=NUM_CLASSES\n)\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:27.809979Z","iopub.execute_input":"2026-02-26T18:46:27.810169Z","iopub.status.idle":"2026-02-26T18:46:31.668871Z","shell.execute_reply.started":"2026-02-26T18:46:27.810150Z","shell.execute_reply":"2026-02-26T18:46:31.668297Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea88b3ea8bd453885faf72ee6b34b80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ed0e87be38e49478fc1bfb374926939"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Segformer(\n  (encoder): MixVisionTransformerEncoder(\n    (patch_embed1): OverlapPatchEmbed(\n      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n    )\n    (patch_embed2): OverlapPatchEmbed(\n      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    )\n    (patch_embed3): OverlapPatchEmbed(\n      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n    )\n    (patch_embed4): OverlapPatchEmbed(\n      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (block1): Sequential(\n      (0): Block(\n        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=64, out_features=64, bias=True)\n          (kv): Linear(in_features=64, out_features=128, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=64, out_features=64, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=64, out_features=256, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=256, out_features=64, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=64, out_features=64, bias=True)\n          (kv): Linear(in_features=64, out_features=128, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=64, out_features=64, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.004)\n        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=64, out_features=256, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=256, out_features=64, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=64, out_features=64, bias=True)\n          (kv): Linear(in_features=64, out_features=128, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=64, out_features=64, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.007)\n        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=64, out_features=256, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=256, out_features=64, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n    (block2): Sequential(\n      (0): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=128, out_features=128, bias=True)\n          (kv): Linear(in_features=128, out_features=256, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.011)\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=128, out_features=128, bias=True)\n          (kv): Linear(in_features=128, out_features=256, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.015)\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=128, out_features=128, bias=True)\n          (kv): Linear(in_features=128, out_features=256, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.019)\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): Block(\n        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=128, out_features=128, bias=True)\n          (kv): Linear(in_features=128, out_features=256, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=128, out_features=128, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.022)\n        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=128, out_features=512, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=512, out_features=128, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n    (block3): Sequential(\n      (0): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.026)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.030)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.033)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.037)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.041)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.044)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.048)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.052)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.056)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.059)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.063)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.067)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (12): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.070)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (13): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.074)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (14): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.078)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (15): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.081)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (16): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.085)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (17): Block(\n        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=320, out_features=320, bias=True)\n          (kv): Linear(in_features=320, out_features=640, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=320, out_features=320, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n        )\n        (drop_path): DropPath(drop_prob=0.089)\n        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n    (block4): Sequential(\n      (0): Block(\n        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=512, out_features=512, bias=True)\n          (kv): Linear(in_features=512, out_features=1024, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Identity()\n          (norm): Identity()\n        )\n        (drop_path): DropPath(drop_prob=0.093)\n        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): Block(\n        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=512, out_features=512, bias=True)\n          (kv): Linear(in_features=512, out_features=1024, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Identity()\n          (norm): Identity()\n        )\n        (drop_path): DropPath(drop_prob=0.096)\n        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): Block(\n        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (q): Linear(in_features=512, out_features=512, bias=True)\n          (kv): Linear(in_features=512, out_features=1024, bias=True)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=512, out_features=512, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n          (sr): Identity()\n          (norm): Identity()\n        )\n        (drop_path): DropPath(drop_prob=0.100)\n        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (dwconv): DWConv(\n            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n          )\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n  )\n  (decoder): SegformerDecoder(\n    (mlp_stage): ModuleList(\n      (0): MLP(\n        (linear): Linear(in_features=512, out_features=256, bias=True)\n      )\n      (1): MLP(\n        (linear): Linear(in_features=320, out_features=256, bias=True)\n      )\n      (2): MLP(\n        (linear): Linear(in_features=128, out_features=256, bias=True)\n      )\n      (3): MLP(\n        (linear): Linear(in_features=64, out_features=256, bias=True)\n      )\n    )\n    (fuse_stage): Conv2dReLU(\n      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (segmentation_head): SegmentationHead(\n    (0): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n    (2): Activation(\n      (activation): Identity()\n    )\n  )\n)"},"metadata":{}}],"execution_count":9},{"id":"26c928cf","cell_type":"code","source":"loss_fn = smp.losses.DiceLoss(mode=\"multiclass\") + \\\n          smp.losses.SoftCrossEntropyLoss()\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=40\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:31.669713Z","iopub.execute_input":"2026-02-26T18:46:31.669985Z","iopub.status.idle":"2026-02-26T18:46:31.677563Z","shell.execute_reply.started":"2026-02-26T18:46:31.669956Z","shell.execute_reply":"2026-02-26T18:46:31.676642Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/423750799.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiceLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0msmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'DiceLoss' and 'SoftCrossEntropyLoss'"],"ename":"TypeError","evalue":"unsupported operand type(s) for +: 'DiceLoss' and 'SoftCrossEntropyLoss'","output_type":"error"}],"execution_count":10},{"id":"0d3a4ff9","cell_type":"code","source":"def compute_iou(pred, mask):\n    pred = torch.argmax(pred, dim=1)\n\n    ious = []\n    for cls in range(NUM_CLASSES):\n        intersection = ((pred == cls) & (mask == cls)).sum().item()\n        union = ((pred == cls) | (mask == cls)).sum().item()\n        if union == 0:\n            continue\n        ious.append(intersection / union)\n    return np.mean(ious)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:31.678152Z","iopub.status.idle":"2026-02-26T18:46:31.678375Z","shell.execute_reply.started":"2026-02-26T18:46:31.678267Z","shell.execute_reply":"2026-02-26T18:46:31.678280Z"}},"outputs":[],"execution_count":null},{"id":"1e0fb7b8","cell_type":"code","source":"best_iou = 0\nEPOCHS = 40\n\nfor epoch in range(EPOCHS):\n    model.train()\n    train_loss = 0\n\n    for imgs, masks in tqdm(train_loader):\n        imgs, masks = imgs.to(device), masks.to(device)\n\n        preds = model(imgs)\n        loss = loss_fn(preds, masks)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    scheduler.step()\n\n    # Validation\n    model.eval()\n    val_iou = []\n\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            preds = model(imgs)\n            val_iou.append(compute_iou(preds, masks))\n\n    mean_iou = np.mean(val_iou)\n\n    print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {train_loss/len(train_loader):.4f} | Val IoU: {mean_iou:.4f}\")\n\n    if mean_iou > best_iou:\n        best_iou = mean_iou\n        torch.save(model.state_dict(), \"best_model.pth\")\n        print(\"Saved best model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-26T18:46:31.679811Z","iopub.status.idle":"2026-02-26T18:46:31.680284Z","shell.execute_reply.started":"2026-02-26T18:46:31.680092Z","shell.execute_reply":"2026-02-26T18:46:31.680118Z"}},"outputs":[],"execution_count":null}]}